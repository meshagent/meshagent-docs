---
title: "TaskRunner"
---

import CliTaskRunnerYaml from "/snippets/examples/cli/taskrunner/meshagent.mdx"
import LLMTaskRunnerService from "/snippets/examples/python/agents/taskrunner/llm_taskrunners_service.mdx"
import ScratchDockerfile from "/snippets/examples/python/deployable/Dockerfile.mdx"
import TaskRunnerYaml from "/snippets/examples/python/deployable/taskrunner/meshagent.mdx"
import PrebuiltTaskRunner from "/snippets/examples/python/agents/taskrunner/prebuilt_taskrunner.mdx"
import PrebuiltTaskRunnerSchema from "/snippets/examples/python/agents/taskrunner/prebuilt_taskrunner_schema.mdx"

## Overview
A `TaskRunner` is a type of agent that's exposed as a tool. When a TaskRunner joins a room, it registers a toolkit that humans and agents can invoke with structured input and receive structured output. Each TaskRunner exposes a single tool named `run_<agent_name>_task`.

A `TaskRunner` defines:
- **Input schema**: JSON Schema describing the arguments your tool accepts
- **Output schema** (optional): JSON Schema describing what your tool returns
- **`ask()` method**: the code that performs the task and returns the result

Once registered in a room, you can invoke the TaskRunner tool from:
- **MeshAgent Studio** (Room menu → **Toolkits…**)
- **CLI** (`meshagent room agents invoke-tool`)
- **SDK** (`room.agents.invoke_tool(...)`)

Most users should start with **`LLMTaskRunner`**, a built-in TaskRunner implementation that uses an LLM (and optional tools) to produce a response. MeshAgent also provides a `DynamicLLMTaskRunner` which lets the caller supply a dynamic output schema per request. 

The `meshagent task-runner` CLI command spins up an `LLMTaskRunner` by default, and MeshAgent ships a prebuilt LLMTaskRunner, `meshagent.runner`, and DynamicLLMTaskRunner, `meshagent.schema_planner`, that are available in every room.

### How to think about TaskRunners
The base `TaskRunner` is intentionally minimal which allows you to **bring-your-own-logic**. You can use it to wrap custom code as a tool that other agents or humans in the room can invoke. For example, you might create a TaskRunner and implement its `ask()` method to run agents from other frameworks (Pydantic AI, LangChain, CrewAI), perform simple business operations (calculations, validations), make API calls, run database queries, or custom workflows. 

**This guide focuses on `LLMTaskRunner`** which extends the base TaskRunner by adding LLM reasoning (and optional tools). 

**Three ways to use LLMTaskRunner:**
1. **Built-in instances** - `meshagent.runner` (LLMTaskRunner) and `meshagent.schema_planner` (DynamicLLMTaskRunner) are pre-deployed in every room
2. **CLI** - Launch your own instance via `meshagent task-runner join` with custom tools/rules  
3. **SDK** - Extend `LLMTaskRunner` or `DynamicLLMTaskRunner` for custom logic

The `LLMTaskRunner` uses a fixed output schema defined at initialization (default: text response) while the `DynamicLLMTaskRunner` uses an output schema provided per-request, allowing different response structures for each task.

If you need a multi-turn conversation, use [ChatBot](./chatbot). For real-time speech, use [VoiceBot](./voicebot). For background queue work, use [Worker](./worker) and for email use [MailBot](./mailbot).

### In this guide you will learn
- When to use `TaskRunner` (specifically `LLMTaskRunner`)
- How to invoke built-in TaskRunner tools using the CLI, SDK, or Studio
- How to run and deploy a TaskRunner with the MeshAgent CLI
- How to build and deploy an `LLMTaskRunner` with the MeshAgent SDK
- How `TaskRunner` works, including lifecycle, task flow, and core hooks

## When to use TaskRunner
Use a TaskRunner when you need an agent that:
- **Exposes a callable tool** with structured input and output
- **Accepts JSON schema input**, and optionally enforces an output schema
- **Can be invoked by other agents or humans** (for example a `ChatBot` calling a TaskRunner tool)

TaskRunners excel when:
- Inputs and outputs are well-defined
- The task doesn’t require multi-turn clarification with a user
- You want a clean context window on each invocation
- You’re running background jobs, batch tasks, or creating callable tools for other agents

The `TaskRunner` class is intentionally minimal so you can bring your own logic or integrate agents from existing frameworks without rewriting them for MeshAgent. It provides the wiring for:
- **Schema-defined inputs and outputs** (validation and discoverability in Studio and SDKs)
- **Room lifecycle and routing** (registration, invocation, and error handling)
- **Tool resolution** (optional toolkits from the room or caller)

You implement `ask(...)` and supply schemas, and MeshAgent handles the rest.

## Using built-in TaskRunners 
MeshAgent ships two TaskRunners that are automatically available in every room:
- `meshagent.runner` (an `LLMTaskRunner` instance) - Accepts a prompt and optional tools, returns text response in `{"result": "..."}` format.
- `meshagent.schema_planner` (a `DynamicLLMTaskRunner` instance) - Accepts a prompt and an `output_schema`, returns structured JSON matching that schema.

You can invoke these tools from the CLI (via `meshagent room agents invoke-tool`), from code (use the `room.agents.invoke_tool()` method), or from [MeshAgent Studio](https://studio.meshagent.com). 

TaskRunners show up as a toolkit named after the agent with a single tool named `run_<agent_name>_task` (use `meshagent room agents list-toolkits` or `room.agents.list_toolkits()` to confirm names and see the available agents).

> **Note**: If you invoke either agent using the MeshAgent SDK you will need to create and export a `MESHAGENT_API_KEY`. You can do this by running `meshagent api-key create <KEY_NAME> --activate` then `export MESHAGENT_API_KEY="your_unique_key"`. If you want to go back to using the regular CLI commands after this you will need to run `unset MESHAGENT_API_KEY` then reauthenticate by running `meshagent setup`. 

### Invoking `meshagent.runner` programmatically

<CodeGroup>
   ```bash CLI
    meshagent room agents invoke-tool \
    --room quickstart \
    --toolkit meshagent.runner \
    --tool run_meshagent.runner_task \
    --arguments '{"prompt":"Write a product description for a bluetooth speaker", "tools":[], "model":null}'
    ```
    <PrebuiltTaskRunner />
</CodeGroup>

> **Note**: When you run this from the MeshAgent CLI, it automatically connects to the room and waits for the agent to join before sending the task. If you’re calling the agent from a language SDK (like Python or JavaScript), you might occasionally see an error such as “agent not in room” if the TaskRunner hasn’t joined yet. In that case, just wait a few seconds and retry once the agent is connected.

### Invoking `meshagent.schema_planner` programatically 

<CodeGroup>
    ```bash CLI
    meshagent room agents invoke-tool \
    --room quickstart \
    --toolkit meshagent.schema_planner \
    --tool run_meshagent.schema_planner_task \
    --arguments '{"prompt":"Create a product listing","output_schema":{"type":"object", "additionalProperties": false, "required": ["title", "price", "features", "description"], "properties": {"title": {"type": "string"}, "price": {"type": "number"}, "features": {"type": "array", "items": {"type": "string"}}, "description": {"type": "string"}}}}'
    ```
    <PrebuiltTaskRunnerSchema />
</CodeGroup>

### Invoke from MeshAgent Studio
1. Go to [MeshAgent Studio](https://studio.meshagent.com)
2. Enter your room
3. Menu → **Toolkits...** → select the `meshagent.runner`
4. Enter prompt and add tools or files to the agent if desired. These can be built-in MeshAgent tools like the UI tools, or other tools you have called into your room to test.
5. Click **Continue** you'll be prompted to fill in the prompt for the TaskRunner.

## Run and deploy a TaskRunner with the CLI
### Step 1: Run a `TaskRunner` from the CLI
This starts a local `LLMTaskRunner` with optional tools and rules.

```bash bash
# Authenticate to MeshAgent if not already signed in
meshagent setup

# Call a task runner into your room
meshagent task-runner join --room quickstart --agent-name mytaskrunner --web-search --storage --room-rules "agents/mytaskrunner/rules.txt" --rule "You are a helpful assistant"
```

When you add the `--room-rules "agents/mytaskrunner/rules.txt"` flag and supply a file path for the rules, the file will be created if it does not already exist. This file is relative to room storage.

> **Tip:** Use `meshagent task-runner join --help` to see all available tools and options.

### Step 2: Invoke the TaskRunner
You can invoke the TaskRunner from MeshAgent Studio or from the CLI just like the built-in TaskRunners.
1. Go to [MeshAgent Studio](https://www.studio.meshagent.com) and log in
2. Enter your room `quickstart`
3. Open the **Toolkits...** menu, select `mytaskrunner`, and submit a prompt

You can also invoke the task runner from the CLI:
```bash bash
meshagent room agents invoke-tool --room quickstart --toolkit mytaskrunner --tool run_mytaskrunner_task --arguments '{"prompt":"Draft a short product description for a bluetooth speaker", "tools":[], "model":null}'
```

### Step 3: Package and deploy the agent
Once your agent works locally, deploy it as a room or project service. Create a `meshagent.yaml` file:

<CodeGroup>
    <CliTaskRunnerYaml />
</CodeGroup>

Then deploy it:
```bash bash
meshagent service create --file meshagent.yaml --room quickstart
```

## Build and deploy a TaskRunner with the SDK
### Step 1: Create a TaskRunner
This example shows how to create your own `LLMTaskRunner` and `DynamicLLMTaskRunner` instances using `ServiceHost`. These work like the built-in `meshagent.runner` and `meshagent.schema_planner`.

<CodeGroup>
    <LLMTaskRunnerService />
</CodeGroup>

### Step 2: Call the agent into a room
Run the agent locally and connect it to a room:
```bash
meshagent setup # authenticate to MeshAgent
meshagent service run "main.py" --room=quickstart
```

### Step 3: Invoke the TaskRunner
From a different tab in your terminal invoke either the `LLMTaskRunner` or `DynamicLLMTaskRunner` from the CLI: 


<CodeGroup>
    ```bash LLMTaskRunner
    meshagent room agents invoke-tool \
    --room myroom \
    --toolkit llmtaskrunner \
    --tool run_llmtaskrunner_task \
    --arguments '{"prompt":"Write a poem about ai agents", "tools":[],"model":null}'
    ```

    ```bash DynamicLLMTaskRunner
    meshagent room agents invoke-tool \
    --room myroom \
    --toolkit dynamicllmtaskrunner \
    --tool run_dynamicllmtaskrunner_task \
    --arguments '{"prompt":"Create a product listing for a bluetooth speaker","output_schema":{"type":"object","additionalProperties":false,"required":["title","price","features","description"],"properties":{"title":{"type":"string"},"price":{"type":"number"},"features":{"type":"array","items":{"type":"string"}},"description":{"type":"string"}}}}'
    ```
</CodeGroup>


### Step 4: Package and deploy the agent
To deploy your SDK TaskRunner permanently, you'll package your code with a `meshagent.yaml` file that defines the service configuration and a container image that MeshAgent can run.
For full details on the service spec and deployment flow, see [Packaging Services](../../services_room_containers/packaging) and [Deploying Services](../../services_room_containers/deployment).

MeshAgent supports two deployment patterns for containers:
1. **Runtime image + code mount (recommended)**: Use a pre-built MeshAgent runtime image (like `python-sdk-slim`) that contains Python and all MeshAgent dependencies. Mount your lightweight code-only image on top. This keeps your code image tiny (~KB), eliminates dependency installation time, and allows your service to start quickly.
2. **Single Image**: Bundle your code and all dependencies into one image. This is good when you need to install additional libraries, but can result in larger images and slower pulls. If you build your own images we recommend [optimizing them with eStargz](../../services_room_containers/containers/optimizing_containers).

This example uses the runtime image + code mount pattern with the public `python-docs-examples` code image so you can run the documentation sample without building your own image. If you want to build and push your own code image, follow the steps below and update the `storage.images` entry in `meshagent.yaml`.

**Prepare your project structure**
This example organizes the agent code and configuration in the same folder, making each agent self-contained:

```bash
your-project/
├── Dockerfile                    # Shared by all samples
├── taskrunner/
│   ├── llm_taskrunners_service.py
│   └── meshagent.yaml           # Config specific to this sample
└── another_sample/              # Other samples follow same pattern
    ├── another_sample.py
    └── meshagent.yaml
```

> **Note:** If you're building a single agent, you only need the `taskrunner/` folder. The structure shown supports multiple samples sharing one Dockerfile.

**Step 4a: Build a Docker container**
If you want a code-only image, create a scratch Dockerfile and copy the files you want to run. This creates a minimal image that pairs with the runtime image + code mount pattern.

<CodeGroup>
    <ScratchDockerfile />
</CodeGroup>

Build and push the image with `docker buildx`:

```bash bash
docker buildx build . \
  -t "<REGISTRY>/<NAMESPACE>/<IMAGE_NAME>:<TAG>" \
  --platform linux/amd64 \
  --push
```

> **Note:** Building from the project root copies your entire project structure into the image. For a single agent, this is fine - your image will just contain one folder. For multi-agent projects, all agents will be in one image, but each can deploy independently using its own `meshagent.yaml`.

**Step 4b: Package the agent**
Define the service configuration in a `meshagent.yaml` file.

<CodeGroup>
    <TaskRunnerYaml />
</CodeGroup>

How the paths work:
- Your code image contains `taskrunner/llm_taskrunners_service.py`
- It's mounted at `/src` in the runtime container
- The command runs `python /src/taskrunner/llm_taskrunners_service.py`

> Note: The default YAML in the docs uses `us-central1-docker.pkg.dev/meshagent-public/images/python-docs-examples` so you can test this example immediately without building your own image first. Replace this with your actual image tag when deploying your own code.

**Step 4c: Deploy the agent**
Next from the CLI in the directory where your `meshagent.yaml` file is run:

```bash
meshagent service create --file "meshagent.yaml" --room=quickstart
```

The TaskRunner is now deployed to the `quickstart` room! Now the agent will always be available inside the room for us to run tasks.

## How TaskRunner Works
### TaskRunner vs LLMTaskRunner
- `TaskRunner` is the base class. You implement `ask(...)` and define input/output schemas.
- `LLMTaskRunner` or `DynamicLLMTaskRunner` is a concrete implementation that calls an LLM adapter, resolves toolkits, and returns the model output.
- The CLI `task-runner` command builds an `LLMTaskRunner` for you.

### Constructor Parameters
`TaskRunner` accepts everything from `SingleRoomAgent` (`name`, `title`, `description`, `requires`, `labels`) plus task-specific configuration.

| Parameter         | Type                    | Description                                                                                      |
| ---------------- | ----------------------- | ------------------------------------------------------------------------------------------------ |
| `supports_tools` | `bool \| None`          | Whether callers can pass ad-hoc toolkits at runtime (default `False`).                           |
| `input_schema`   | `dict`                  | **Required.** JSON Schema for request arguments. If `None`, defaults to a no-args schema.       |
| `output_schema`  | `dict \| None`          | Optional JSON Schema for responses; if set, responses are validated.                             |
| `toolkits`       | `list[Toolkit] \| None` | Local toolkits always available to this TaskRunner (in addition to any `requires`).              |

`LLMTaskRunner` adds LLM-specific parameters like `llm_adapter`, `tool_adapter`, `rules`, `client_rules`, and `input_prompt`.

### Lifecycle Overview
`TaskRunner` inherits lifecycle hooks from `SingleRoomAgent` and adds toolkit registration and routing.

- `await start(room: RoomClient)`: Registers the TaskRunner toolkit and tool, installs requirements, and enables routing.
- `await stop()`: Unregisters the toolkit if the protocol is open, then disconnects cleanly.
- `room` property: Access the active RoomClient as usual.

### Task Flow
When a task is invoked (from Studio or code):
1. The room delivers a tool invocation for `run_<agent_name>_task`.
2. Arguments are validated against `input_schema`.
3. Your `ask(context, arguments)` method runs your logic and returns a dict.
4. If `output_schema` is set, the response is validated before returning to the caller.

### Key Behaviors and Hooks
- **Schema validation:** `validate_arguments()` and `validate_response()` enforce `input_schema` and `output_schema`.
- **Tool support:** When `supports_tools=True`, callers can include tool configs per request. `LLMTaskRunner` uses these to build toolkits for the LLM.
- **Discovery:** Registration exposes your TaskRunner's schema and capabilities to Studio, CLI, and other agents so they are discoverable and invokable.

### Key Methods
| Method                                      | Description                                                            |
| ------------------------------------------- | ---------------------------------------------------------------------- |
| `async def ask(context, arguments) -> dict` | Implement your task logic and return a JSON-serializable dict.        |
| `async def validate_arguments(arguments)`   | Validates inputs against `input_schema`.                               |
| `async def validate_response(response)`     | Validates outputs against `output_schema` when provided.               |
| `async def start(room)` / `async def stop()`| Registers/unregisters the runner and protocol handlers.                |
| `def to_json()`                             | Serializes metadata (schemas, flags, labels) used during registration. |

## Next Steps
- [Use an existing agent with a TaskRunner](./taskrunner_agents_and_tools)
- [ChatBot](./chatbot) for conversation-based agents
- [VoiceBot](./voicebot) for voice-based agents
- [Worker](./worker) for background queue processing
