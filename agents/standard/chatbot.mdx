---
title: "ChatBot Overview"
---

import SimpleChatbot from "/snippets/examples/python/agents/chatbot/simple_chatbot.mdx"

`ChatBot` builds on [`SingleRoomAgent`](./singleroomagent) to deliver a ready-to-use conversational agent. It joins a MeshAgent room, manages per-participant chat threads, streams responses from your chosen LLM, and persists conversation history so users can pick up where they left off. Toolkit integration, thread storage, and auto-greeting are all handled for you, which makes `ChatBot` the fastest path to creating a helpful, interactive chat-based agent. The MeshAgent `ChatBot` supports both static and dynamic toolkits built per message. This allows you to define tools the agent should always have access to as well as add and remove tools on demand as a conversation progresses. 

## When to Use It
- You want to build an agent that is **seamlessly connected to the room** and **responds conversationally** to user messages.
- You're building a **text-based agent that uses an LLM** to generate responses. 
- You need to **synchronize message history** with room documents or threads. 
- You want automatic integration with toolkits and schemas for dynamic LLM behavior.
- You plan to add tools, dynamic UI interactions, or other agent-to-room interactions during a chat.
- You prefer to focus on prompts, tools, and business logic for your agent instead of plumbing for storage, messaging, and scale.

If your agent only needs to perform background tasks or doesn’t interact with participants directly, consider subclasses like [Worker](./worker) or [TaskRunner](./taskrunner) instead.

## Constructor Parameters
`ChatBot` accepts everything that `SingleRoomAgent` does (`name`, `title`, `description`, `requires`, `labels`) and adds chat-specific parameters.

| Parameter             | Type                          | Description                                                                                                     |
| -------------------- | ----------------------------- | --------------------------------------------------------------------------------------------------------------- |
| `name`               | `str`                         | Unique identifier for the agent within the room.                                                                |
| `title`              | `str \| None`                 | Human-friendly name shown in UX. Defaults to `name`.                                                            |
| `description`        | `str \| None`                 | Optional short description.                                                                                     |
| `requires`           | `list[Requirement] \| None`   | Dependencies such as `RequiredSchema` or `RequiredToolkit`. Automatically ensures the `"thread"` schema exists. |
| `llm_adapter`        | `LLMAdapter`                  |  Required. Adapter that talks to your model provider (for example `OpenAIResponsesAdapter`). It supplies chat contexts and translates responses into MeshAgent events.                                      |
| `tool_adapter`       | `ToolResponseAdapter \| None` | Optional adapter for translating tool call outputs.                                                             |
| `toolkits`           | `list[Toolkit] \| None`       | Extra toolkits that are always available to the ChatBot beyond what `requires` installs. Defaults to `[]`.                                                     |
| `rules`              | `list[str] \| None`           | List of system or behavior rules appended to each chat context.                                                 |
| `auto_greet_message` | `str \| None`                 | Optional greeting message sent automatically by the agent when a new thread starts.                                                     |
| `empty_state_title`  | `str \| None`                 | Title text shown in the Studio chat pane before the first user message. Defaults to `"How can I help you?"`.                                        |
| `labels`             | `list[str] \| None`           | Optional tags for discovery and filtering.                                                                      |

If you do not pass a `requires` list, `ChatBot` automatically injects `RequiredSchema(name="thread")` so it can store transcripts. You can still add additional toolkits or schemas by supplying your own list.

## Lifecycle Overview
``ChatBot`` inherits the lifecycle from ``SingleRoomAgent`` but extends it to manage ongoing conversations and message threads.

- ``await start(room: RoomClient)``: Connects to the room, installs requirements, and registers message handlers. Spawns per-thread tasks to handle participant messages, LLM responses, and tool invocations.
-   ``await stop()``: Cancels active chat threads and clears cached state before disconnecting.
- ``room`` property: Accesses the active RoomClient just like in SingleRoomAgent.

## Conversation Flow 
When a participant sends a message:
1. The ChatBot receives the message via ``room.messaging.on("message")``.
2. It identifies or spawns a chat thread corresponding to that conversation path.
3. A chat context (``AgentChatContext``) is initialized using the ``llm_adapter``.
4. The message history is synchronized with the room’s ``"thread"`` document.
5. ChatBot resolves this turn’s toolkits: it collects `ToolkitBuilder`s from `get_toolkit_builders(...)`, merges per-turn `ToolkitConfig`s (from MeshAgent Studio/CLI/App UI), calls `make_tools(...)` to create any dynamic toolkits, and combines the result with any static toolkits.
6. The LLM is invoked with the prepared chat context and the resolved toolkits; tool calls are routed back into those toolkits, tokens are streamed, and the results are appended to the thread document.

All of this happens automatically once your bot is started.

## Key Behaviors and Hooks
- **Thread management:** Every conversation lives inside a MeshDocument thread. The ChatBot opens the thread as soon as a user sends a message and keeps it in sync with the document store.
- **Context building:** `init_chat_context()` asks the LLM adapter for a fresh context and appends any rules you provided. Override this if you need to preload the context with extra data.
- **Static tool resolution:** `get_thread_toolkits()` gathers toolkits declared in `requires`, and any always-on toolkits passed through `toolkits`.
- **Dynamic tool providers:** `get_toolkit_builders()` lists the `ToolkitBuilder` factories the ChatBot is willing to spin up on demand (MCP, storage uploads, local shell, image generation, etc.). The chat UI calls this hook first to learn which tool toggles to display, and later sends back matching configs so the ChatBot can hydrate those toolkits with `make_tools()`.
- **Message-specific toolkits:** When the user sends a message with a `tools` payload, `make_tools()` combines the selected configs with the provider list to hydrate just the toolkits needed for that turn before the LLM is invoked. (For example, in MeshAgent Studio, when the user selects which tools to add to an agent, these tools are added to the `tools` payload so the agent can use them.)
- **Thread helpers:** Use `open_thread()` and `close_thread()` to work with the underlying document, or `load_thread_context()` to replay the stored messages into an existing chat context (for example, when resuming a conversation).
- **LLM customization:** Override `prepare_llm_context()` if you need to mutate the context right before calling the LLM (for example to provide additional background context for the agent outside of the system prompt).
- **Participant utilities:** `get_online_participants()` returns the participants included in the thread so you can tailor responses or access their attributes.

## Key Methods
| Method                                                         | Description                                                                                 |
| -------------------------------------------------------------- | ------------------------------------------------------------------------------------------- |
| `async def init_chat_context()`                                | Creates a new chat context using the configured `llm_adapter` and applies rules.            |
| `async def get_thread_toolkits(thread_context, participant)`   | Resolves all always-on toolkits for a participant, including built-in reasoning tools.      |
| `def get_toolkit_builders()`                                   | Returns the `ToolkitBuilder` list the UI can offer for message-level tool selection.         |
| `async def open_thread(path)` / `async def close_thread(path)` | Opens or closes a thread document in the room.                                              |
| `async def load_thread_context(thread_context)`                | Loads historical messages into the current chat context from the thread document.           |
| `async def prepare_llm_context(thread_context)`                | Hook for modifying the chat context before invoking the LLM. Override as needed.            |

## Built-in Toolkits and Behaviors
``ChatBot`` automatically provides and manages several toolkits and utilities:
- **Reasoning Toolkit:** Allows structured “chain-of-thought” reasoning within the chat context.
- **Built-in Tool Support (OpenAI-style):** May include web_search, local_shell, or image_gen, depending on the LLM adapter.
- **UI Toolkit Integration:** Supports sending messages, showing toasts, or interacting with user interfaces via the "ui" toolkit.

These can be extended or replaced with your own toolkit factories.

### Multi-user threads and reply logic

ChatBot is multi-user aware out of the box. Conversation state is stored in a `thread` document (a room-synced XML-like structure) with two key sections:
- `<members>`: participant names for this thread. The client UI (e.g., [MeshAgent Studio](https://studio.meshagent.com), [Powerboards](https://www.powerboards.com/), or your app) writes this list, the ChatBot only reads it.
- `<messages>`: conversation history, attachments, tool output. The ChatBot appends messages here as it responds.

When a message arrives:
1. The UI opens a thread path (via `room.sync.open(path, create=true)`) and writes the `<members>` list for that conversation.
2. ChatBot opens the same document and syncs changes.
3. ChatBot cross-references `<members>` with the current online roster from `room.messaging.get_participants()` to see who is actually present.
4. If more than one human is in the thread, ChatBot runs the `should_reply` function to determine whether the assistant is the intended next speaker. If not, it stays quiet. With a single human, the ChatBot always replies.

Private vs group chats:
- If the thread has one human in `<members>`, the chatbot treats it like a 1:1 and replies.
- If the thread has more than one human in `<members>`, it automatically switches to multiplayer mode and uses `should_reply` to decide whether to speak.

## Beginner-Friendly Examples

<CodeGroup>
    <SimpleChatbot />
</CodeGroup>


This subclass uses the OpenAI Responses API and applies a a system prompt. You can call the ChatBot into a room directly from your terminal by running: 

```bash bash 
meshagent service run "main.py" --room=gettingstarted
``` 

Next from the [MeshAgent Studio](https://studio.meshagent.com) you can go to the **Sessions** tab, open the **gettingstarted** room, and begin chatting with your agent. 

To extend the Chatbot with Tools see the next article on [building a chat agent](./buildanddeploychatbot).

MeshAgent Studio and the Flutter SDK include built-in chat UI components (such as ``ChatThreadLoader``) that understand ChatBot threads. This means any conversation started in the Studio can be displayed properly or continued inside your own application without extra integration work.

## Next Steps

``ChatBot`` builds directly on ``SingleRoomAgent``, inheriting its lifecycle management, requirement installation, and toolkit resolution. While ``SingleRoomAgent`` focuses on room connection and environment setup, ``ChatBot`` handles conversation orchestration — managing threads, participants, messages, and reasoning.

To continue learning about MeshAgent agents check out:

- [Build a ChatBot](./buildanddeploychatbot): Step-by-step guide to configuring adapters, adding toolkits, and running your ChatBot in a MeshAgent room.
- [Adapters](../adapters/index): Understand how LLM adapters and tool response adapters plug into the chat loop.
- [VoiceBot](./voicebot): Adds streaming audio input/output for speech interactions.
- [Worker](./worker) and [TaskRunner](./taskrunner): Perform background or task-based actions.
- [MailBot](./MailBot): Interact with an agent via email.

To learn more about deploying agents with MeshAgent
- [Services & Containers](../../services_room_containers/overview): Understand different options for running, deploying, and managing agents with MeshAgent
- [Secrets & Registries](../../secrets/secrets_overview): Learn how to store credentials securely for deployment


Use ``ChatBot`` whenever your agent’s primary interface is text-based conversation and you need a foundation for more specialized conversational agents.
