---
title: "TaskRunner"
---

import PydanticAgents from "/snippets/examples/python/agents/taskrunner/pydantic_agents.mdx"
import InvokingTaskRunner from "/snippets/examples/python/agents/taskrunner/invoking_taskrunner.mdx"
import PrebuiltTaskRunner from "/snippets/examples/python/agents/taskrunner/prebuilt_taskrunner.mdx"
import PrebuiltTaskRunnerSchema from "/snippets/examples/python/agents/taskrunner/prebuilt_taskrunner_schema.mdx"
import LLMTaskRunners from "/snippets/examples/python/agents/taskrunner/llm_taskrunners.mdx"
import LLMTaskRunnerService from "/snippets/examples/python/agents/taskrunner/llm_taskrunners_service.mdx"
import InvokeLLMTaskRunner from "/snippets/examples/python/agents/taskrunner/invoking_llm_taskrunner.mdx"


A TaskRunner is the bridge that makes any **existing AI Agent built in your framework of choice work seamlessly with MeshAgent**. It is a base agent class designed with one core principle: **bring your own logic**. 

## Why TaskRunner Exists

Many developers already have agents built with their preferred frameworks—whether that's Pydantic AI, LangChain, CrewAI, or custom implementations. TaskRunner eliminates the need to rewrite these agents. Instead, you simply wrap your existing agent with a TaskRunner and can instantly share, deploy, scale, and manage your agents in a cohesive way. 

## Core Components

A TaskRunner defines: 
- **Input Schema**: JSON schema describing what arguments your agent accepts
- **Output Schema**: JSON schema describing what your agent returns
- **Ask Method**: Your custom logic that processes inputs and returns results (``room.agents.ask()``)

A TaskRunner joins a MeshAgent Room and can be discovered and invoked from the [MeshAgent Studio](https://studio.meshagent.com) using the "Run Task..." menu option or using the ```room.agents.ask``` method on the API.

## Example: Integrating a Pydantic AI Agent

This example shows how to wrap an existing Pydantic AI translation agent with a MeshAgent TaskRunner. We extend the base TaskRunner class to create our TranslationTaskRunner with a defined input schema, output schema, and ask method. 

### Building the Pydantic AI based TaskRunner
Copy this code into a file called ``translator.py``. You will need to create and export an ``ANTHROPIC_API_KEY`` first for this to run.

<CodeGroup>
    <PydanticAgents />
</CodeGroup>

### Running the TaskRunner

**In your terminal**

Start your service locally. Be sure you are in an activated virtual environment where meshagent and pydantic_ai are installed: 

```bash bash
python translator.py
```

Next use the MeshAgent CLI to authenticate and call your agent into a Room:
```bash bash
meshagent setup # this will authenticate you 
meshagent call agent --url=http://localhost:7777/translator --room=translate --participant-name=translator
```

**In the Studio**
1. Go to [studio.meshagent.com](https://studio.meshagent.com) 
2. Enter the room, ``translate``
3. Click menu --> "Run Task"
4. Select "translator" from the agent dropdown 
5. Enter the text to translate
6. Results appear and are saved to room storage under the "translations" folder 

**Invoking the TaskRunner Programmatically**

Instead of invoking the agent through the Studio, you can also run the agent through code like this. Let's create a file called ``invoke_translator.py``: 

<CodeGroup>
    <InvokingTaskRunner />
</CodeGroup>

From the terminal run:
```bash bash
meshagent env # you need to export the env variables first to invoke tools from code like this
python invoke_translator.py
```

You will see the result logged to your terminal and saved in the room. 


## Example: Using TaskRunner Agents as Agent Tools
TaskRunners can also be surfaced in toolkits and used as tools by other agents using ``RunTaskTool``. Exposing agents as tools and then giving those tools to a ChatBot is a great way to get started building multi-agent systems. 

Let's try this out by creating a new ChatBot and giving it a tool, the Pydantic AI translation agent that we defined above. 

### Creating the service with agents-as-tools
At the end of our ``translator.py`` file all we have to add is the new ChatBot service and pass it the ``translator`` agent as a ``RequiredToolkit``.

```python Python
@service.path("/chatwithtools")
class ChatBotAgentTools(ChatBot):
    def __init__(self):
        super().__init__(
            name="mychatbot",
            llm_adapter=OpenAIResponsesAdapter(),
            requires=[RequiredToolkit(name="agents", tools=["translator"])],
        )
```

### Running an agent with agents-as-tools

Run your python file with both the translator and the chatbot:

```bash bash
python translator.py
```

Call both agents into the room: 

```bash bash
meshagent setup #authenticate if not already connected
meshagent call agent --url=http://localhost:7777/translator --room=translate --participant-name=translator
meshagent call agent --url=http://localhost:7777/chatwithtools --room=translate --participant-name=chatagent
```

### Using the agent with agents as tools

**In the Studio**:
1. Go to [studio.meshagent.com](https://studio.meshagent.com)
2. Enter the room translate
3. In the participants list, you'll see the ``chatagent``
4. Click on ``chatagent`` to start chatting with the agent
5. Ask it something like: "Can you translate 'Hello, how are you?' for me?"
6. The ``chatagent`` will automatically use the ``translator`` agent as a tool to complete the request and you will see the JSON results added to the translations folder in the room storage. 

*Remember: You can still use the translator agent directly since it is running in the room, this approach just demonstrates an easy way to use agents as tools*

## Example: Prebuilt MeshAgent TaskRunners
MeshAgent provides pre-built agents that extend the TaskRunner class with additional capabilities like tool use and iterative reasoning. These built-in agents are automatically available in every MeshAgent room as ``meshagent.planner`` and ``meshagent.schema_planner``.

### meshagent.planner
A TaskRunner that uses structured planning and returns a text response. You provide it a prompt (and optionally tools), and it yields a simple text response in a fixed schema: ``{"result":"<text>"}``. 

Example without tools: 

<CodeGroup>
    <PrebuiltTaskRunner />
</CodeGroup>


When you call tools into the studio you can add them to the generic meshagent.planner which is automatically available in the room. The Planner will ask you for any necessary information and invoke the appropriate tool(s) to perform the task. This is a good way to test how the tools you've built work with agents. 

### meshagent.schema_planner
A TaskRunner that uses structured planning and returns a structured output. You provide both a prompt and an explicit JSON schema describing the desired output.

Example without tools: 
<CodeGroup>
    <PrebuiltTaskRunnerSchema />
</CodeGroup>

Two preconfigured task runners are available by default in MeshAgent rooms. These are available as ```meshagent.planner``` and ```meshagent.schema_planner``` via the ```room.agents.ask``` api.
You can try them out in the Studio by selecting "Run Task..." from the menu. These built in agents can be useful helpers in your own apps. For example, when you invoke an agent inside the
MeshAgent Studio, the PlanningResponder is used to generate user interface on the fly and gather the required JSON data to pass as input when invoking an agent. Extending the base TaskRunner 
and providing a custom set of rules and tools is a great way to get a simple agent up and running quickly.


## Example: Custom TaskRunners using an LLM
We can easily extend the TaskRunner into an LLM powered agent that returns a response once the LLM's execution loop finishes. Let's take a look at the ``LLMTaskRunner`` and ``DynamicLLMTaskRunner`` which allow you to use either a fixed response schema or a caller-supplied one.  

### How does a TaskRunner change when an LLM is involved? 
1. **Chat Context**: Add a step to spin up the conversation using the ``init_chat_context`` method
2. **LLM Call Loop**: Create an ask() function that allows the model to work until the task is finished (we do this by calling ``.next()`` on the ``LLMAdapter`` in the ask function)
3. **Schema Validation**: Validate the LLM output against the declared schema to ensure consistency.

### LLMTaskRunner and DynamicLLMTaskRunner
``LLMTaskRunner`` uses a fixed output schema defined at initialization time and always returns data in the same format. By default it takes in a text prompt and returns a string response. The ``DynamicLLMTaskRunner`` accepts an output_schema parameter at runtime, allowing different structured outputs for different requests.

#### Key Constructor Parameters
- **llm_adapter:** a LLM adapter to use to integrate with a LLM. We recommend using the OpenAIResponsesAdapter from ```meshagent-openai```.
- **supports_tools** Whether the agent should support passing a custom set of tools at runtime (optional)
- **tool_adapter:** a custom tool adapter to use to transform tool responses into context messages (optional).
- **toolkits:** used to specify local toolkits for the agent. While it's generally recommended to register toolkits with the room so any agent or user can use them, sometimes you need each agent to have it's own instance of a toolkit, for instance with synchorized document authoring.
- **requires:** a list of requirements for the agent. You can use RequiredSchema, RequiredToolkit to use toolkits and schemas that have been registered with the room with this agent.
- **input_prompt:** Whether the TaskRunner should accept a prompt as input, if true, the input should be in the format ```{ "prompt" : "text" }```.
- **input_schema:** JSON schema describing what arguments your agent accepts. If not provided and input_prompt is True, defaults to a prompt schema accepting text.
- **output_schema:** For ``LLMTaskRunner`` only, a JSON schema that responses must conform to (by default returns ``{"result": {"type": "string"}}``). In ``DynamicLLMTaskRunner`` the ``output_schema`` is set dynamically at runtime. 
- **rules:** a set of rules that the task runner should use while executing. Rules are used to guide the behavior of the agent with system or developer prompts (optional).

#### Class Definition
The following class definitions show how to implement both LLMTaskRunner and DynamicLLMTaskRunner. These classes handle the LLM execution loop, schema validation, and toolkit integration:

<CodeGroup>
    <LLMTaskRunners />
</CodeGroup>

#### Service Implementation
Here's a complete example of implementing an ``LLMTaskRunner`` that uses an OpenAI model that takes a text input prompt and returns a string text response. 

The ``DynamicLLMTaskRunner`` also uses an OpenAI model but returns a schema defined at runtime.

<CodeGroup>
    <LLMTaskRunnerService />
</CodeGroup>

**Running the Custom TaskRunners**

Run the py file in one tab:
```bash bash
python llm_taskrunner.py
```

Call the agents into the room in another: 
```bash bash
meshagent setup #authenticate if not already connected
meshagent call agent --url=http://localhost:7777/llmtaskrunner --room=myroom --participant-name=llmtaskrunner
meshagent call agent --url=http://localhost:7777/dynamicllmtaskrunner --room=myroom --participant-name=dynamicllmtaskrunner
```

**Using the LLMTaskRunner from the Studio**
1. Go to [studio.meshagent.com](https://studio.meshagent.com)
2. Enter the room, myroom
3. Click menu —> “Run Task”
4. Select “LLM Task Runner” from the agent dropdown
4a. Optionall click "add tools" and add tools to your new LLMTaskRunner
5. Enter a prompt
6. Results appear 

**Using the DynamicLLMTaskRunner Programmatically**

<CodeGroup>
    <InvokeLLMTaskRunner />
</CodeGroup>
